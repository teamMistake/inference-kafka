{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services import JamoService\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"hg_tokenizer\")\n",
    "jamo = JamoService(\"../../inference_server/model_store/production_A.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del jamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jamo import JAMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "model = JAMO.from_pretrained(\"small\", \"../../inference_server/model_store/production_A.tar\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"너는 누구니?\", \"안녕 반가워, 내 이름은 윤승현이라고 해.\", \"너가 가장 좋아하는 음식은?\"]\n",
    "\n",
    "def parsing_prmopt(instruction):\n",
    "    chat_parser = (\n",
    "        \"명령어에 따른 요청을 적절히 완료하는 응답을 작성하세요.\\n\\n\"\n",
    "        \"### 명령어:\\n{instruction}\\n\\n### 응답:\\n\"\n",
    "    )\n",
    "\n",
    "    parsed_prompt = chat_parser.format_map({\"instruction\":instruction})\n",
    "    return parsed_prompt\n",
    " \n",
    "# idxs = torch.LongTensor([])\n",
    "idxs = []\n",
    "max_length = 0\n",
    "for prompt in prompts:\n",
    "    parsed_prmopt = parsing_prmopt(prompt)\n",
    "    parsed_prmopt = f\"<s> {parsed_prmopt}\"\n",
    "    \n",
    "    idx = tokenizer.encode(parsed_prmopt)\n",
    "    # idxs = torch.cat((idx, ))\n",
    "    idxs.append(idx)\n",
    "    if max_length < len(idx) : max_length = len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_for_multibatch(idx):\n",
    "tmp = []\n",
    "for idx in idxs:\n",
    "    new = [1] * (max_length - len(idx)) + idx + [1] * (256-max_length)\n",
    "    tmp.append(new)\n",
    "\n",
    "target = torch.LongTensor(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 8000])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 8000])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re = result[:, -1, :]\n",
    "print(re.shape)\n",
    "probs = torch.nn.functional.softmax(re, dim=-1)\n",
    "\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_idx = torch.multinomial(probs, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1]), torch.Size([3, 256]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_idx.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[723],\n",
      "        [723],\n",
      "        [723]])\n",
      "1\n",
      "tensor([[273],\n",
      "        [273],\n",
      "        [273]])\n",
      "2\n",
      "tensor([[414],\n",
      "        [585],\n",
      "        [397]])\n",
      "3\n",
      "tensor([[705],\n",
      "        [380],\n",
      "        [634]])\n",
      "4\n",
      "tensor([[886],\n",
      "        [705],\n",
      "        [800]])\n",
      "5\n",
      "tensor([[853],\n",
      "        [384],\n",
      "        [341]])\n",
      "6\n",
      "tensor([[ 373],\n",
      "        [2307],\n",
      "        [3744]])\n",
      "7\n",
      "tensor([[ 553],\n",
      "        [1185],\n",
      "        [3605]])\n",
      "8\n",
      "tensor([[490],\n",
      "        [ 16],\n",
      "        [341]])\n",
      "9\n",
      "tensor([[280],\n",
      "        [608],\n",
      "        [479]])\n"
     ]
    }
   ],
   "source": [
    "cur = max_length - 1\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    result = model(target)\n",
    "\n",
    "    re = result[:, cur, :]\n",
    "    probs = torch.nn.functional.softmax(re, dim=-1)\n",
    "\n",
    "    next_token_idx = torch.multinomial(probs, num_samples=1)\n",
    "    cur += 1\n",
    "    # print(target[:, cur].shape, next_token_idx.squeeze(1).shape)\n",
    "    print(next_token_idx)\n",
    "    \n",
    "    target[:, cur] = next_token_idx.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = target[0].unsqueeze(0)\n",
    "\n",
    "for i in range(10):\n",
    "    result = model(t)\n",
    "\n",
    "    re = result[:, cur, :]\n",
    "    probs = torch.nn.functional.softmax(re, dim=-1)\n",
    "\n",
    "    next_token_idx = torch.multinomial(probs, num_samples=1)\n",
    "    cur += 1\n",
    "    \n",
    "    t[:, cur] = next_token_idx.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = torch.empty((3, 10), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.randn((3, 5)).to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0, -1,  0,  0],\n",
       "        [ 0,  0,  0,  2, -1],\n",
       "        [ 1, -1,  0,  1,  0]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty[range(3),: 5] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0, -1,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  2, -1,  0,  0,  0,  0,  0],\n",
       "        [ 1, -1,  0,  1,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.arange(0, 10)\n",
    "input_pos = torch.stack([pos, pos, pos], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10],\n",
       "        [10],\n",
       "        [10]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_pos[:,  -1:]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[-1:]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index_copy_(): Number of indices (10) should be equal to source.size(dim) (1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yoonseonghyeon/Desktop/deeplearning/inference_kafka/app/experiments.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yoonseonghyeon/Desktop/deeplearning/inference_kafka/app/experiments.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m5\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yoonseonghyeon/Desktop/deeplearning/inference_kafka/app/experiments.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m idx\u001b[39m.\u001b[39;49mindex_copy(\u001b[39m0\u001b[39;49m, pos, torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m10\u001b[39;49m]))\n",
      "\u001b[0;31mIndexError\u001b[0m: index_copy_(): Number of indices (10) should be equal to source.size(dim) (1)"
     ]
    }
   ],
   "source": [
    "idx = torch.arange(5)\n",
    "idx.index_copy(0, pos, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_next = torch.tensor([1,3,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_next == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a[idx_next==0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1.])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(idx_next!=0, a, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.any(torch.tensor([0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.ones((2, 5)).to(torch.long)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.index_select(1, torch.arange(0, 3)).view(2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index_copy_(): When source and destination are not scalars, their dimensionality must match. Source dimensionality (1), destination dimensionality (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yoonseonghyeon/Desktop/deeplearning/inference_kafka/app/experiments.ipynb Cell 35\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yoonseonghyeon/Desktop/deeplearning/inference_kafka/app/experiments.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m idx\u001b[39m.\u001b[39;49mindex_copy(\u001b[39m1\u001b[39;49m, torch\u001b[39m.\u001b[39;49marange(\u001b[39m0\u001b[39;49m, \u001b[39m3\u001b[39;49m), torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m]))\n",
      "\u001b[0;31mIndexError\u001b[0m: index_copy_(): When source and destination are not scalars, their dimensionality must match. Source dimensionality (1), destination dimensionality (2)"
     ]
    }
   ],
   "source": [
    "idx.index_copy(1, torch.arange(0, 3), torch.tensor([2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index_copy_(): When source is scalar, index should have one element (got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yoonseonghyeon/Desktop/deeplearning/inference_kafka/app/experiments.ipynb Cell 36\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yoonseonghyeon/Desktop/deeplearning/inference_kafka/app/experiments.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m idx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones(\u001b[39m4\u001b[39m)\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yoonseonghyeon/Desktop/deeplearning/inference_kafka/app/experiments.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m idx\u001b[39m.\u001b[39;49mindex_copy(\u001b[39m0\u001b[39;49m, torch\u001b[39m.\u001b[39;49marange(\u001b[39m0\u001b[39;49m, \u001b[39m3\u001b[39;49m), torch\u001b[39m.\u001b[39;49mtensor(\u001b[39m10\u001b[39;49m)\u001b[39m.\u001b[39;49mto(torch\u001b[39m.\u001b[39;49mlong))\n",
      "\u001b[0;31mIndexError\u001b[0m: index_copy_(): When source is scalar, index should have one element (got 3)"
     ]
    }
   ],
   "source": [
    "idx = torch.ones(4).to(torch.long)\n",
    "idx.index_copy(0, torch.arange(0, 3), torch.tensor(10).to(torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([True, True, True]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.ones((2, 5))\n",
    "print(idx)\n",
    "idx[:, range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [[1, 2, 3], [71, 16, 2], [400, 50, 20]]\n",
    "\n",
    "v, _ = torch.topk(torch.tensor(t), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3],\n",
       "        [ 71],\n",
       "        [400]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-inf, -inf,   3.],\n",
       "        [ 71., -inf, -inf],\n",
       "        [400., -inf, -inf]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(torch.tensor(t) < v[:, [-1]], -float(\"Inf\"), torch.tensor(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros(3)[torch.tensor([723, 723, 723])==2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index_copy_(): Number of indices (1) should be equal to source.size(dim) (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yoonseonghyeon/Desktop/deeplearning/inference_kafka/app/experiments.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yoonseonghyeon/Desktop/deeplearning/inference_kafka/app/experiments.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49mones((\u001b[39m2\u001b[39;49m, \u001b[39m3\u001b[39;49m), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong)\u001b[39m.\u001b[39;49mindex_copy(\u001b[39m0\u001b[39;49m, torch\u001b[39m.\u001b[39;49mtensor(\u001b[39m2\u001b[39;49m), torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m4\u001b[39;49m],[\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39m3\u001b[39;49m]]))\n",
      "\u001b[0;31mIndexError\u001b[0m: index_copy_(): Number of indices (1) should be equal to source.size(dim) (2)"
     ]
    }
   ],
   "source": [
    "torch.ones((2, 3), dtype=torch.long).index_copy(1, torch.tensor(2), torch.tensor([[0, 0, 4],[0, 0, 3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d2639ffb07810fac2cedc92e08a41c0bae42ca785c48ccdb21dd6b5e60bd2fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
